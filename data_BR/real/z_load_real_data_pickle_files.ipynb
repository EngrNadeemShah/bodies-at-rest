{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# set np print options\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Files & Directories (Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk('.'):\n",
    "    print(f'Root: {root}')\n",
    "    print()\n",
    "\n",
    "    print(f'Directories:')\n",
    "    for i, dir in enumerate(dirs):\n",
    "        print(f'Directory ({i+1:2d}/{len(dirs)}): {dir}')\n",
    "    print()\n",
    "\n",
    "    print(f'Files:')\n",
    "    for i, file in enumerate(files):\n",
    "        print(f'File ({i+1:2d}/{len(files)}): {file}')\n",
    "    print('______________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Files -> All Keys (shape / len / value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk('.'):\n",
    "\n",
    "    if root == '.':\n",
    "        continue\n",
    "\n",
    "    print(f'Root: {root}')\n",
    "    print('______________________________________________________')\n",
    "\n",
    "    for f_no, file in enumerate(files):\n",
    "        if file.endswith('.p'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f'File ({f_no+1:2d}/{len(files)}): {file_path}')\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f, encoding='latin1')\n",
    "            \n",
    "            for i, (k, v) in enumerate(data.items()):\n",
    "                print(f'Key ({i+1:2d}/{len(data)}): {k}\\t| ', end='')\n",
    "                if isinstance(v, str):\n",
    "                    print(f'str: {v}')\n",
    "                elif isinstance(v, float):\n",
    "                    print(f'float: {v}')\n",
    "                else:\n",
    "                    try:\n",
    "                        print(f'array: {np.array(v).shape}')\n",
    "                    except:\n",
    "                        print(f'len: {len(v)}')\n",
    "\n",
    "            print('______________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save __p_select.p__ & __prescribed.p__ to a __Spreadsheet__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __p_select.p__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p_select = []\n",
    "\n",
    "for root, dirs, files in os.walk('.'):\n",
    "\n",
    "    if root == '.':\n",
    "        continue\n",
    "\n",
    "    row = {'Subject': root.lstrip('.\\\\')}\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "\n",
    "        if file.endswith('participant_info_red.p'):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f, encoding='latin1')\n",
    "            \n",
    "            for k, v in data.items():\n",
    "\n",
    "                if k == 'height_in' or k == 'gender' or k == 'weight_lbs':\n",
    "                    row[k] = v\n",
    "\n",
    "                elif k == 'prescribed_pose_type' or k == 'p_select_pose_type':\n",
    "                    row[k] = v\n",
    "\n",
    "\n",
    "        if file.endswith('p_select.p'):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "            for k, v in data.items():\n",
    "\n",
    "                if k == 'pmat_corners' or k == 'depth' or k == 'RGB' or k == 'images':\n",
    "                    row[k] = np.array(v).shape\n",
    "\n",
    "                elif k == 'pose_type':\n",
    "                    row[k+'_len'] = len(v)\n",
    "\n",
    "                elif k == 'pc':\n",
    "                    pc_lens = [np.array(pc).shape for pc in v]\n",
    "                    row[k] = pc_lens\n",
    "\n",
    "\n",
    "            data_p_select.append(row)\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df_p_select = pd.DataFrame(data_p_select)\n",
    "\n",
    "# # Save to CSV\n",
    "# df_p_select.to_csv('real_data_p_select.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __prescribed.p__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prescribed = []\n",
    "\n",
    "for root, dirs, files in os.walk('.'):\n",
    "\n",
    "    if root == '.':\n",
    "        continue\n",
    "\n",
    "    row = {'Subject': root.lstrip('.\\\\')}\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "\n",
    "        if file.endswith('participant_info_red.p'):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f, encoding='latin1')\n",
    "            \n",
    "            for k, v in data.items():\n",
    "\n",
    "                if k == 'height_in' or k == 'gender' or k == 'weight_lbs':\n",
    "                    row[k] = v\n",
    "\n",
    "                elif k == 'prescribed_pose_type' or k == 'p_select_pose_type':\n",
    "                    row[k] = v\n",
    "\n",
    "\n",
    "        if file.endswith('prescribed.p'):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "            for k, v in data.items():\n",
    "\n",
    "                if k == 'pmat_corners' or k == 'depth' or k == 'RGB' or k == 'images':\n",
    "                    row[k] = np.array(v).shape\n",
    "\n",
    "                elif k == 'pose_type':\n",
    "                    row[k+'_len'] = len(v)\n",
    "\n",
    "                elif k == 'pc':\n",
    "                    pc_lens = [np.array(pc).shape for pc in v]\n",
    "                    row[k] = pc_lens\n",
    "\n",
    "\n",
    "            data_prescribed.append(row)\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df_prescribed = pd.DataFrame(data_prescribed)\n",
    "\n",
    "# # Save to CSV\n",
    "# df_prescribed.to_csv('real_data_prescribed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('real_data.xlsx') as writer:\n",
    "    df_p_select.to_excel(writer, sheet_name='p_select', index=False)\n",
    "    df_prescribed.to_excel(writer, sheet_name='prescribed', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __participant_info_red.p__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate the Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists to store the statistics\n",
    "height_in               = []\n",
    "gender                  = []\n",
    "weight_lbs              = []\n",
    "prescribed_pose_type    = []\n",
    "p_select_pose_type      = []\n",
    "\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        if file.endswith('participant_info_red.p'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f'File: {file_path}')\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f, encoding='latin1')\n",
    "            \n",
    "            for i, (k, v) in enumerate(data.items()):\n",
    "                print(f'Key ({i+1:2d}/{len(data)}): {k}')\n",
    "                if k == 'height_in':\n",
    "                    height_in.append(v)\n",
    "                elif k == 'gender':\n",
    "                    gender.append(v)\n",
    "                elif k == 'weight_lbs':\n",
    "                    weight_lbs.append(v)\n",
    "                elif k == 'prescribed_pose_type':\n",
    "                    prescribed_pose_type.append(v)\n",
    "                elif k == 'p_select_pose_type':\n",
    "                    p_select_pose_type.append(v)\n",
    "                else:\n",
    "                    print(f'Key: {k} not found')\n",
    "\n",
    "            print('______________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print the Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to numpy arrays\n",
    "height_in_arr   = np.array(height_in)\n",
    "gender_arr      = np.array(gender)\n",
    "weight_lbs_arr  = np.array(weight_lbs)\n",
    "\n",
    "print(f'Height Statistics:')\n",
    "print(f'Mean:   {np.mean(height_in_arr):.2f}')\n",
    "print(f'Median: {np.median(height_in_arr):.2f}')\n",
    "print(f'Std:    {np.std(height_in_arr):.2f}')\n",
    "print(f'Min:    {np.min(height_in_arr):.2f}')\n",
    "print(f'Max:    {np.max(height_in_arr):.2f}')\n",
    "print()\n",
    "\n",
    "print(f'Weight Statistics:')\n",
    "print(f'Mean:   {np.mean(weight_lbs_arr):.2f}')\n",
    "print(f'Median: {np.median(weight_lbs_arr):.2f}')\n",
    "print(f'Std:    {np.std(weight_lbs_arr):.2f}')\n",
    "print(f'Min:    {np.min(weight_lbs_arr):.2f}')\n",
    "print(f'Max:    {np.max(weight_lbs_arr):.2f}')\n",
    "print()\n",
    "\n",
    "# Count the genders\n",
    "gender_unique = np.unique(gender_arr, return_counts=True)\n",
    "print(f'Gender Count:')\n",
    "print(f'Unique: {gender_unique[0]}')\n",
    "print(f'Counts: {gender_unique[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the height distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(height_in_arr)\n",
    "plt.title('Height Distribution')\n",
    "plt.xlabel('Height (in)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid()\n",
    "\n",
    "# Plot the weight distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(weight_lbs_arr)\n",
    "plt.title('Weight Distribution')\n",
    "plt.xlabel('Weight (lbs)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack the prescribed_pose_type\n",
    "prescribed_pose_type_unpacked = []\n",
    "\n",
    "for i, lst in enumerate(prescribed_pose_type):\n",
    "    for j, elem in enumerate(lst):\n",
    "        # print(f'Participant {i+1:2d} | Pose {j+1:2d} | {elem}')\n",
    "        prescribed_pose_type_unpacked.append(elem)\n",
    "    # print(f'Participant {i+1:2d} | Pose Count: {len(lst)}')\n",
    "\n",
    "print(f'Prescribed Pose Type Unpacked:')\n",
    "print(f'Length: {len(prescribed_pose_type_unpacked)}')\n",
    "print(f'Length (Calculated): {(48*20)-2-3-3}')\n",
    "print(f'Unique: {np.unique(prescribed_pose_type_unpacked)}')\n",
    "print(f'Counts: {np.unique(prescribed_pose_type_unpacked, return_counts=True)[1]}')\n",
    "print()\n",
    "\n",
    "\n",
    "# Unpack the p_select_pose_type\n",
    "p_select_pose_type_unpacked = []\n",
    "\n",
    "for i, lst in enumerate(p_select_pose_type):\n",
    "    for j, elem in enumerate(lst):\n",
    "        # print(f'Participant {i+1:2d} | Pose {j+1:2d} | {elem}')\n",
    "        p_select_pose_type_unpacked.append(elem)\n",
    "    # print(f'Participant {i+1:2d} | Pose Count: {len(lst)}')\n",
    "\n",
    "print(f'P Select Pose Type Unpacked:')\n",
    "print(f'Length: {len(p_select_pose_type_unpacked)}')\n",
    "print(f'Length (Calculated): {(5*20)-1}')\n",
    "print(f'Unique: {np.unique(p_select_pose_type_unpacked)}')\n",
    "print(f'Counts: {np.unique(p_select_pose_type_unpacked, return_counts=True)[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print the Missing Poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the directories (subjects)\n",
    "directories = [entry for entry in os.listdir() if os.path.isdir(entry)]\n",
    "\n",
    "print(f'Missing Prescribed Poses:')\n",
    "print(f'All Subjects have 48 poses, except for the following:')\n",
    "print(f'Subject 04 (dir: {directories[4-1]}) has 46 poses')\n",
    "print(f'Subject 14 (dir: {directories[14-1]}) has 45 poses')\n",
    "print(f'Subject 19 (dir: {directories[19-1]}) has 45 poses')\n",
    "print()\n",
    "\n",
    "print(f'Missing P Select Poses:')\n",
    "print(f'All Subjects have 5 poses, except for the following:')\n",
    "print(f'Subject 11 (dir: {directories[11-1]}) has 4 poses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the directories (subjects)\n",
    "directories = [entry for entry in os.listdir() if os.path.isdir(entry)]\n",
    "\n",
    "# Select a random directory\n",
    "rand_dir = np.random.choice(directories)\n",
    "\n",
    "# Load the file from the random directory (subject)\n",
    "file_path = os.path.join(rand_dir, 'participant_info_red.p')\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file, encoding='latin1')\n",
    "\n",
    "# Inspect the data\n",
    "print(f'File Path: {file_path}')\n",
    "print(f'Type of Data: {type(data)}')\n",
    "print()\n",
    "\n",
    "for i, (k, v) in enumerate(data.items()):\n",
    "    print(f'Key ({i+1}): {k}')\n",
    "    print(f'Value: {v}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __p_select.p__ or __prescribed.p__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a random file from the random (subject) directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = 'p_select.p'\n",
    "# file_type = 'prescribed.p'\n",
    "\n",
    "# # Create a list of all the directories (subjects)\n",
    "# directories = [entry for entry in os.listdir() if os.path.isdir(entry)]\n",
    "\n",
    "# # Select a random directory\n",
    "# rand_dir = np.random.choice(directories)\n",
    "\n",
    "# Load the file from the random directory (subject)\n",
    "file_path = os.path.join(rand_dir, file_type)\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file, encoding='latin1')\n",
    "\n",
    "# Inspect the data\n",
    "print(f'File Path: {file_path}')\n",
    "print(f'Type of Data: {type(data)}')\n",
    "print()\n",
    "\n",
    "# Calculate the number of examples\n",
    "length = len(list(data.values())[0])\n",
    "print(f'Number of Examples: {length}')\n",
    "\n",
    "# Select a random example\n",
    "rand_example = np.random.randint(length)\n",
    "print(f'Random Example: {rand_example + 1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Keys -> All Examples (Shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, v) in enumerate(data.items()):\n",
    "    print(f'Key ({i+1}): {k}')\n",
    "\n",
    "    for i, e in enumerate(v):\n",
    "        try:\n",
    "            print(f'Example: {i+1:2d} | Type: {type(e)} | Shape: {e.shape}')\n",
    "        except:\n",
    "            print(f'Example: {i+1:2d} | Type: {type(e)} | Value: {e}')\n",
    "    print('______________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key (1): pmat_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the key (pmat_corners)\n",
    "pmat_corners = data['pmat_corners']\n",
    "\n",
    "# Load the pressure map corners of the random example\n",
    "pmat_corners = pmat_corners[rand_example]\n",
    "\n",
    "# Inspect the pressure map corners\n",
    "print(f'Pressure Map Corners Shape: {pmat_corners.shape}')\n",
    "print(f'Pressure Map Corners (Original):')\n",
    "print(pmat_corners)\n",
    "print()\n",
    "\n",
    "\n",
    "# Extract the x and y coordinates\n",
    "x = pmat_corners[:, 0]\n",
    "y = pmat_corners[:, 1]\n",
    "\n",
    "# Calculate the minimum and maximum values of x and y\n",
    "x_min = x.min()\n",
    "x_max = x.max()\n",
    "y_min = y.min()\n",
    "y_max = y.max()\n",
    "\n",
    "# Round the minimum and maximum values of x and y to the nearest hundred\n",
    "x_min_round = math.floor(x_min/100)*100\n",
    "x_max_round = math.ceil(x_max/100)*100\n",
    "y_min_round = math.floor(y_min/100)*100\n",
    "y_max_round = math.ceil(y_max/100)*100\n",
    "\n",
    "# Calculate the pressure map corners\n",
    "bottom_left\t\t= tuple(np.round(pmat_corners[0]))\n",
    "bottom_right\t= tuple(np.round(pmat_corners[1]))\n",
    "top_left\t\t= tuple(np.round(pmat_corners[2]))\n",
    "top_right\t\t= tuple(np.round(pmat_corners[3]))\n",
    "\n",
    "\n",
    "# Inspect the minimum and maximum values of x and y\n",
    "print(f'Min and Max Values (Original):')\n",
    "print(f'x min: {x_min:.2f}')\n",
    "print(f'x max: {x_max:.2f}')\n",
    "print(f'y min: {y_min:.2f}')\n",
    "print(f'y max: {y_max:.2f}')\n",
    "print()\n",
    "\n",
    "# Inspect the rounded minimum and maximum values of x and y\n",
    "print(f'Min and Max Values (Rounded to the Nearest Hundred):')\n",
    "print(f'x min round: {x_min_round}')\n",
    "print(f'x max round: {x_max_round}')\n",
    "print(f'y min round: {y_min_round}')\n",
    "print(f'y max round: {y_max_round}')\n",
    "print()\n",
    "\n",
    "# Inspect the pressure map corners\n",
    "print(f'Pressure Map Corners: (Rounded and Labelled)')\n",
    "print(f'Bottom Left:\t{bottom_left}')\n",
    "print(f'Bottom Right:\t{bottom_right}')\n",
    "print(f'Top Left:\t{top_left}')\n",
    "print(f'Top Right:\t{top_right}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key (2): pose_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the key (pose_type)\n",
    "pose_type = data['pose_type']\n",
    "\n",
    "# Inspect the pose type\n",
    "print(f'Pose Type:')\n",
    "for i, p in enumerate(pose_type):\n",
    "    print(f'Pose ({i+1:2d}): {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images:\n",
    "- Key (1): pmat_corners\n",
    "- Key (3): depth\n",
    "- Key (5): RGB\n",
    "- Key (6): images (PM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the keys (pmat_corners, depth, RGB and images) of the random example\n",
    "pmat_corners\t= data['pmat_corners'][rand_example]\n",
    "depth\t\t\t= data['depth'][rand_example]\n",
    "rgb\t\t\t\t= data['RGB'][rand_example]\n",
    "pm\t\t\t\t= data['images'][rand_example]\n",
    "\n",
    "# Rotate the depth image 90 degrees\n",
    "depth_rot = np.rot90(depth)\n",
    "\n",
    "# Resize the pressure map image to match the depth (rotated) image shape\n",
    "pm_padded   = np.pad(pm, ((0, 0), (2, 3)), mode='constant', constant_values=pm.max())\n",
    "pm_reshaped = np.resize(pm_padded, (depth_rot.shape[0], depth_rot.shape[1]))\n",
    "\n",
    "\n",
    "# Print the depth, pressure map and RGB images shapes\n",
    "print(f'Depth (Original) Shape:         {depth.shape}')\n",
    "print(f'Depth Rotated Shape:            {depth_rot.shape}')\n",
    "print(f'RGB Shape:                      {rgb.shape}')\n",
    "print(f'Pressure Map (Original) Shape:  {pm.shape}')\n",
    "print(f'Pressure Map (Padded) Shape:    {pm_padded.shape}')\n",
    "print(f'Pressure Map (Reshaped) Shape:  {pm_reshaped.shape}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the depth, pressure map and RGB images\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.suptitle(f'Depth, Pressure Map and RGB Images ({rand_example + 1}/{length})')\n",
    "\n",
    "# Display depth image\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(depth_rot, cmap='gray')\n",
    "plt.title(f'Depth')\n",
    "# plt.axis('off')\n",
    "\n",
    "# Display RGB image\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(rgb)\n",
    "plt.title(f'RGB')\n",
    "# plt.axis('off')\n",
    "\n",
    "# Display pressure map image (padded)\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(pm_padded, cmap='gray')\n",
    "plt.title(f'Pressure Map (Padded)')\n",
    "# plt.axis('off')\n",
    "\n",
    "# Display pressure map image (reshaped)\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(pm_reshaped, cmap='gray')\n",
    "plt.title(f'Pressure Map (Reshaped)')\n",
    "# plt.axis('off')\n",
    "\n",
    "# Display pressure map image (Original)\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(pm, cmap='gray')\n",
    "plt.title(f'Pressure Map (Original)')\n",
    "# plt.axis('off')\n",
    "\n",
    "# Display pressure map corners\n",
    "# Along with labels for the corners (Top Left, Top Right, Bottom Left, Bottom Right)\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.plot(x, y, 'or')\n",
    "plt.title('Pressure Map Corners')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.xlim(x_min_round, x_max_round)\n",
    "plt.ylim(y_min_round, y_max_round)\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.text(pmat_corners[0, 0], pmat_corners[0, 1], 'Bottom Left',     fontsize=12, color='b')\n",
    "plt.text(pmat_corners[1, 0], pmat_corners[1, 1], 'Bottom Right',    fontsize=12, color='b')\n",
    "plt.text(pmat_corners[2, 0], pmat_corners[2, 1], 'Top Left',        fontsize=12, color='b')\n",
    "plt.text(pmat_corners[3, 0], pmat_corners[3, 1], 'Top Right',       fontsize=12, color='b')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Padding & Resizing Calculations (Rough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_rot_shape = depth_rot.shape\n",
    "pm_shape = pm.shape\n",
    "print(f'Depth Rotated Shape: {depth_rot_shape}')\n",
    "print(f'Pressure Map Shape: {pm_shape}')\n",
    "\n",
    "# Calculate the inter-image ratio\n",
    "depth_rot_ratio = depth_rot_shape[0] / depth_rot_shape[1]\n",
    "pm_ratio = pm_shape[0] / pm_shape[1]\n",
    "\n",
    "# Calculate the inter-axis ratio\n",
    "x_ratio = depth_rot_shape[0] / pm_shape[0]\n",
    "y_ratio = depth_rot_shape[1] / pm_shape[1]\n",
    "\n",
    "# Inspect the inter-image ratio\n",
    "print(f'Depth Rotated Ratio: {depth_rot_ratio:.2f}')\n",
    "print(f'Pressure Map Ratio: {pm_ratio:.2f}')\n",
    "print()\n",
    "\n",
    "# Inspect the inter-axis ratio\n",
    "print(f'x Ratio: {x_ratio:.2f}')\n",
    "print(f'y Ratio: {y_ratio:.2f}')\n",
    "print()\n",
    "\n",
    "# Pad the pressure map image to match the depth (rotated) image ratio\n",
    "pm_padded = np.pad(pm, ((0, 0), (2, 3)), mode='constant', constant_values=0)\n",
    "pm_padded_shape = pm_padded.shape\n",
    "print(f'Pressure Map Padded Shape: {pm_padded_shape}')\n",
    "print()\n",
    "\n",
    "# Calculate the inter-image ratio\n",
    "pm_padded_ratio = pm_padded_shape[0] / pm_padded_shape[1]\n",
    "print(f'Pressure Map Padded Ratio: {pm_padded_ratio:.2f}')\n",
    "\n",
    "# Calculate the inter-axis ratio\n",
    "x_ratio_padded = depth_rot_shape[0] / pm_padded_shape[0]\n",
    "y_ratio_padded = depth_rot_shape[1] / pm_padded_shape[1]\n",
    "print(f'x Ratio Padded: {x_ratio_padded:.2f}')\n",
    "print(f'y Ratio Padded: {y_ratio_padded:.2f}')\n",
    "print()\n",
    "\n",
    "# Resize the pressure map (padded) image to match the depth (rotated) image shape\n",
    "pm_reshaped = np.resize(pm_padded, (depth_rot_shape[0], depth_rot_shape[1]))\n",
    "pm_reshaped_shape = pm_reshaped.shape\n",
    "print(f'Pressure Map Reshaped Shape: {pm_reshaped_shape}')\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
