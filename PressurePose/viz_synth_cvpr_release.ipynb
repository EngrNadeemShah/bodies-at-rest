{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\bodies-at-rest\\PressurePose\n",
      "D:\\Coding\\bodies-at-rest\\PressurePose\n",
      "d:\\Coding\\bodies-at-rest\\env\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(r'D:\\Coding\\bodies-at-rest\\PressurePose')\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_verts = False\n",
    "seg_limbs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAT_WIDTH = 0.762  # metres\n",
    "MAT_HEIGHT = 1.854  # metres\n",
    "MAT_HALF_WIDTH = MAT_WIDTH / 2\n",
    "NUMOFTAXELS_X = 64  # 73 #taxels\n",
    "NUMOFTAXELS_Y = 27  # 30\n",
    "NUMOFOUTPUTDIMS = 3\n",
    "NUMOFOUTPUTNODES_TRAIN = 24\n",
    "NUMOFOUTPUTNODES_TEST = 10\n",
    "INTER_SENSOR_DISTANCE = 0.0286  # metres\n",
    "LOW_TAXEL_THRESH_X = 0\n",
    "LOW_TAXEL_THRESH_Y = 0\n",
    "HIGH_TAXEL_THRESH_X = (NUMOFTAXELS_X - 1)\n",
    "HIGH_TAXEL_THRESH_Y = (NUMOFTAXELS_Y - 1)\n",
    "TEST_SUBJECT = 9\n",
    "CAM_BED_DIST = 1.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import torch\n",
    "import time\n",
    "import lib_pyrender_basic as libPyRender\n",
    "from chumpy.ch import MatVecMult\n",
    "import chumpy\n",
    "import chumpy as ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\bodies-at-rest\n",
      "D:\\Coding\\bodies-at-rest\\PressurePose\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "print(os.getcwd())\n",
    "from smpl.smpl_webuser.posemapper import posemap\n",
    "from smpl.smpl_webuser.verts import verts_core\n",
    "from smpl.smpl_webuser import lbs\n",
    "os.chdir('PressurePose')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database_file_f: ['../data_BR/synth/quick_test/test_rollpi_f_lay_set23to24_3000_qt_convnet_1_anglesDC_184000ct_128b_x1pm_tnh_clns10p_100e_2e-05lr.p']\n",
      "database_file_m: []\n"
     ]
    }
   ],
   "source": [
    "filepath_prefix = '../data_BR/synth/'\n",
    "GENDER = \"f\"\n",
    "\n",
    "#Replace this with some subset of data of your choice\n",
    "TESTING_FILENAME = 'quick_test/test_rollpi_'+GENDER+'_lay_set23to24_3000_qt_convnet_1_anglesDC_184000ct_128b_x1pm_tnh_clns10p_100e_'+str(0.00002)+'lr'\n",
    "\n",
    "database_file_f = []\n",
    "database_file_m = []\n",
    "\n",
    "if GENDER == \"f\":\n",
    "    database_file_f.append(filepath_prefix+TESTING_FILENAME+'.p')\n",
    "    model_pkl_file_path = '../smpl/models/basicModel_f_lbs_10_207_0_v1.0.0.pkl'\n",
    "else:\n",
    "    database_file_m.append(filepath_prefix+TESTING_FILENAME+'.p')\n",
    "    model_pkl_file_path = '../smpl/models/basicModel_m_lbs_10_207_0_v1.0.0.pkl'\n",
    "\n",
    "\n",
    "print(f'database_file_f: {database_file_f}')\n",
    "print(f'database_file_m: {database_file_m}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. class __PysicalTrainer__()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. def __init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. CTRL_PNL Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTRL_PNL = {}\n",
    "CTRL_PNL['loss_vector_type'] = 'anglesDC'\n",
    "CTRL_PNL['verbose'] = False\n",
    "CTRL_PNL['batch_size'] = 1\n",
    "CTRL_PNL['num_epochs'] = 100\n",
    "CTRL_PNL['incl_inter'] = True\n",
    "CTRL_PNL['shuffle'] = True\n",
    "CTRL_PNL['incl_ht_wt_channels'] = False\n",
    "CTRL_PNL['incl_pmat_cntct_input'] = True\n",
    "CTRL_PNL['dropout'] = False\n",
    "CTRL_PNL['lock_root'] = False\n",
    "CTRL_PNL['num_input_channels'] = 2\n",
    "CTRL_PNL['GPU'] = False\n",
    "CTRL_PNL['regr_angles'] = False\n",
    "CTRL_PNL['aws'] = False\n",
    "CTRL_PNL['depth_map_labels'] = True #can only be true if we have 100% synthetic data for training\n",
    "CTRL_PNL['depth_map_labels_test'] = True #can only be true is we have 100% synth for testing\n",
    "CTRL_PNL['depth_map_output'] = CTRL_PNL['depth_map_labels']\n",
    "CTRL_PNL['depth_map_input_est'] = False  #do this if we're working in a two-part regression\n",
    "CTRL_PNL['adjust_ang_from_est'] = CTRL_PNL['depth_map_input_est'] #holds betas and root same as prior estimate\n",
    "CTRL_PNL['clip_sobel'] = True\n",
    "CTRL_PNL['clip_betas'] = True\n",
    "CTRL_PNL['mesh_bottom_dist'] = True\n",
    "CTRL_PNL['full_body_rot'] = True\n",
    "CTRL_PNL['normalize_input'] = False\n",
    "CTRL_PNL['normalize_per_image'] = False\n",
    "CTRL_PNL['all_tanh_activ'] = True\n",
    "CTRL_PNL['L2_contact'] = True\n",
    "CTRL_PNL['pmat_mult'] = int(1)\n",
    "CTRL_PNL['cal_noise'] = False\n",
    "CTRL_PNL['double_network_size'] = False\n",
    "CTRL_PNL['first_pass'] = True\n",
    "\n",
    "\n",
    "weight_joints = 1.0#opt.j_d_ratio*2\n",
    "weight_depth_planes = (1-0.5)#*2\n",
    "\n",
    "if CTRL_PNL['cal_noise'] == True:\n",
    "    CTRL_PNL['incl_pmat_cntct_input'] = False #if there's calibration noise we need to recompute this every batch\n",
    "    CTRL_PNL['clip_sobel'] = False\n",
    "\n",
    "if CTRL_PNL['incl_pmat_cntct_input'] == True:\n",
    "    CTRL_PNL['num_input_channels'] += 1\n",
    "if CTRL_PNL['depth_map_input_est'] == True: #for a two part regression\n",
    "    CTRL_PNL['num_input_channels'] += 3\n",
    "CTRL_PNL['num_input_channels_batch0'] = np.copy(CTRL_PNL['num_input_channels'])\n",
    "if CTRL_PNL['incl_ht_wt_channels'] == True:\n",
    "    CTRL_PNL['num_input_channels'] += 2\n",
    "if CTRL_PNL['cal_noise'] == True:\n",
    "    CTRL_PNL['num_input_channels'] += 1\n",
    "\n",
    "pmat_std_from_mult = ['N/A', 11.70153502792190, 19.90905848383454, 23.07018866032369, 0.0, 25.50538629767412]\n",
    "if CTRL_PNL['cal_noise'] == False:\n",
    "    sobel_std_from_mult = ['N/A', 29.80360490415032, 33.33532963163579, 34.14427844692501, 0.0, 34.86393494050921]\n",
    "else:\n",
    "    sobel_std_from_mult = ['N/A', 45.61635847182483, 77.74920396659292, 88.89398421073700, 0.0, 97.90075708182506]\n",
    "\n",
    "CTRL_PNL['norm_std_coeffs'] =  [1./41.80684362163343,  #contact\n",
    "                                        1./16.69545796387731,  #pos est depth\n",
    "                                        1./45.08513083167194,  #neg est depth\n",
    "                                        1./43.55800622930469,  #cm est\n",
    "                                        1./pmat_std_from_mult[int(CTRL_PNL['pmat_mult'])], #pmat\n",
    "                                        1./sobel_std_from_mult[int(CTRL_PNL['pmat_mult'])], #pmat sobel\n",
    "                                        1./1.0,                #bed height mat\n",
    "                                        1./1.0,                #OUTPUT DO NOTHING\n",
    "                                        1./1.0,                #OUTPUT DO NOTHING\n",
    "                                        1. / 30.216647403350,  #weight\n",
    "                                        1. / 14.629298141231]  #height\n",
    "\n",
    "\n",
    "CTRL_PNL['filepath_prefix'] = '/home/henry/'\n",
    "    #CTRL_PNL['filepath_prefix'] = '/media/henry/multimodal_data_2/'\n",
    "\n",
    "mat_size = (NUMOFTAXELS_X, NUMOFTAXELS_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Prepare Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. TensorPrepLib().load_files_to_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files_to_database(database_file, creation_type, verbose = False, reduce_data = False, test = False):\n",
    "    # load in the training or testing files.  This may take a while.\n",
    "    dat = None\n",
    "    for some_subject in database_file:\n",
    "        #print creation_type, some_subject, 'some subject'\n",
    "        if creation_type in some_subject:\n",
    "            dat_curr = load_pickle(some_subject)\n",
    "            print(some_subject, dat_curr['bed_angle_deg'][0])\n",
    "            for key in dat_curr:\n",
    "                if np.array(dat_curr[key]).shape[0] != 0:\n",
    "                    for inputgoalset in np.arange(len(dat_curr['images'])):\n",
    "                        datcurr_to_append = dat_curr[key][inputgoalset]\n",
    "                        if key == 'images' and np.shape(datcurr_to_append)[0] == 3948:\n",
    "                            datcurr_to_append = list(\n",
    "                                np.array(datcurr_to_append).reshape(84, 47)[10:74, 10:37].reshape(1728))\n",
    "                        try:\n",
    "                            if test == False:\n",
    "                                if reduce_data == True:\n",
    "                                    if inputgoalset < len(dat_curr['images'])/4:\n",
    "                                        dat[key].append(datcurr_to_append)\n",
    "                                else:\n",
    "                                    dat[key].append(datcurr_to_append)\n",
    "                            else:\n",
    "                                if len(dat_curr['images']) == 3000:\n",
    "                                    if inputgoalset < len(dat_curr['images'])/2:\n",
    "                                        dat[key].append(datcurr_to_append)\n",
    "                                elif len(dat_curr['images']) == 1500:\n",
    "                                    if inputgoalset < len(dat_curr['images'])/3:\n",
    "                                        dat[key].append(datcurr_to_append)\n",
    "                                else:\n",
    "                                    dat[key].append(datcurr_to_append)\n",
    "\n",
    "                        except:\n",
    "                            try:\n",
    "                                dat[key] = []\n",
    "                                dat[key].append(datcurr_to_append)\n",
    "                            except:\n",
    "                                dat = {}\n",
    "                                dat[key] = []\n",
    "                                dat[key].append(datcurr_to_append)\n",
    "\n",
    "    if dat is not None and verbose == True:\n",
    "        for key in dat:\n",
    "            print('all data keys and shape', key, np.array(dat[key]).shape)\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dat_f \u001b[38;5;241m=\u001b[39m \u001b[43mload_files_to_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatabase_file_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreation_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msynth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m dat_m \u001b[38;5;241m=\u001b[39m load_files_to_database(database_file \u001b[38;5;241m=\u001b[39m database_file_m, creation_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynth\u001b[39m\u001b[38;5;124m'\u001b[39m, reduce_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdat_f.keys(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdat_f\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m, in \u001b[0;36mload_files_to_database\u001b[1;34m(database_file, creation_type, verbose, reduce_data, test)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m some_subject \u001b[38;5;129;01min\u001b[39;00m database_file:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#print creation_type, some_subject, 'some subject'\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m creation_type \u001b[38;5;129;01min\u001b[39;00m some_subject:\n\u001b[1;32m----> 7\u001b[0m         dat_curr \u001b[38;5;241m=\u001b[39m \u001b[43mload_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43msome_subject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(some_subject, dat_curr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbed_angle_deg\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dat_curr:\n",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m, in \u001b[0;36mload_pickle\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_pickle\u001b[39m(filename):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dat_f = load_files_to_database(database_file = database_file_f, creation_type = 'synth', reduce_data = False)\n",
    "dat_m = load_files_to_database(database_file = database_file_m, creation_type = 'synth', reduce_data = False)\n",
    "\n",
    "print(f'dat_f.keys(): {dat_f.keys()}')\n",
    "print(f'dat_m: {dat_m}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. TensorPrepLib().prep_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_images(train_x_flat, dat_f, dat_m, num_repeats):\n",
    "    for dat in [dat_f, dat_m]:\n",
    "        if dat is not None:\n",
    "            for entry in range(len(dat['images'])):\n",
    "                for i in range(num_repeats):\n",
    "                    train_x_flat.append(dat['images'][entry])\n",
    "    return train_x_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_flat = []\n",
    "train_x_flat = prep_images(train_x_flat, dat_f, dat_m, num_repeats = 1)\n",
    "train_x_flat = list(np.clip(np.array(train_x_flat) * float(CTRL_PNL['pmat_mult']), a_min=0, a_max=100))\n",
    "\n",
    "print(f'np.array(train_x_flat).shape: {np.array(train_x_flat).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. TensorPrepLib().prep_depth_contact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_depth_contact(depth_contact_maps, dat_f, dat_m, num_repeats):\n",
    "    for dat in [dat_f, dat_m]:\n",
    "        if dat is not None:\n",
    "            for entry in range(len(dat['images'])):\n",
    "                for i in range(num_repeats):\n",
    "                    depth_contact_maps.append([dat['mesh_depth'][entry], dat['mesh_contact'][entry]])\n",
    "    return depth_contact_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CTRL_PNL['depth_map_labels'] == True:\n",
    "    depth_contact_maps = [] # Initialize the precomputed depth and contact maps. only synth has this label.\n",
    "    depth_contact_maps = prep_depth_contact(depth_contact_maps, dat_f, dat_m, num_repeats = 1)\n",
    "else:\n",
    "    depth_contact_maps = None\n",
    "\n",
    "print(f'np.array(depth_contact_maps).shape: {np.array(depth_contact_maps).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. TensorPrepLib().prep_depth_contact_input_est()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_depth_contact_input_est(depth_contact_maps_input_est, dat_f, dat_m, num_repeats):\n",
    "    for dat in [dat_f, dat_m]:\n",
    "        if dat is not None:\n",
    "            for entry in range(len(dat['images'])):\n",
    "                for i in range(num_repeats):\n",
    "                    mdm_est_pos = np.copy(dat['mdm_est'][entry])\n",
    "                    mdm_est_neg = np.copy(dat['mdm_est'][entry])\n",
    "                    mdm_est_pos[mdm_est_pos < 0] = 0\n",
    "                    mdm_est_neg[mdm_est_neg > 0] = 0\n",
    "                    mdm_est_neg *= -1\n",
    "                    # depth_contact_input_est_list.append([dat['mdm_est'][entry], dat['cm_est'][entry]])\n",
    "                    depth_contact_maps_input_est.append([mdm_est_pos, mdm_est_neg, dat['cm_est'][entry]*100])\n",
    "    return depth_contact_maps_input_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CTRL_PNL['depth_map_input_est'] == True:\n",
    "    depth_contact_maps_input_est = [] # Initialize the precomputed depth and contact map input estimates\n",
    "    depth_contact_maps_input_est = prep_depth_contact_input_est(depth_contact_maps_input_est, dat_f, dat_m, num_repeats = 1)\n",
    "else:\n",
    "    depth_contact_maps_input_est = None\n",
    "\n",
    "print(f'CTRL_PNL[depth_map_input_est]: {CTRL_PNL[\"depth_map_input_est\"]}')\n",
    "print(f'np.array(depth_contact_maps_input_est).shape: {np.array(depth_contact_maps_input_est).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. PreprocessingLib().preprocessing_create_pressure_angle_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_create_pressure_angle_stack(train_x_flat, mat_size, CTRL_PNL):\n",
    "    '''This is for creating a 2-channel input using the height of the bed. '''\n",
    "\n",
    "    if CTRL_PNL['verbose']: print(np.max(train_x_flat))\n",
    "    train_x_flat = np.clip(train_x_flat, 0, 100)\n",
    "\n",
    "    print(\"normalizing per image\", CTRL_PNL['normalize_per_image'])\n",
    "\n",
    "    train_xa = []\n",
    "    for map_index in range(len(train_x_flat)):\n",
    "        # print map_index, mat_size, 'mapidx'\n",
    "        # Resize mat to make into a matrix\n",
    "\n",
    "        p_map = np.reshape(train_x_flat[map_index], mat_size)\n",
    "\n",
    "        if CTRL_PNL['normalize_per_image'] == True:\n",
    "            p_map = p_map * (20000./np.sum(p_map))\n",
    "\n",
    "        if mat_size == (84, 47):\n",
    "            p_map = p_map[10:74, 10:37]\n",
    "\n",
    "        # this makes a sobel edge on the image\n",
    "        sx = ndimage.sobel(p_map, axis=0, mode='constant')\n",
    "        sy = ndimage.sobel(p_map, axis=1, mode='constant')\n",
    "        p_map_inter = np.hypot(sx, sy)\n",
    "        if CTRL_PNL['clip_sobel'] == True:\n",
    "            p_map_inter = np.clip(p_map_inter, a_min=0, a_max = 100)\n",
    "\n",
    "        if CTRL_PNL['normalize_per_image'] == True:\n",
    "            p_map_inter = p_map_inter * (20000. / np.sum(p_map_inter))\n",
    "\n",
    "        #print np.sum(p_map), 'sum after norm'\n",
    "        train_xa.append([p_map, p_map_inter])\n",
    "\n",
    "    return train_xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the bed height array on the pressure image as well as a sobel filtered image\n",
    "train_xa = preprocessing_create_pressure_angle_stack(train_x_flat, mat_size, CTRL_PNL)\n",
    "\n",
    "print(f'np.array(train_xa).shape: {np.array(train_xa).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. TensorPrepLib().append_input_depth_contact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_input_depth_contact(train_xa, CTRL_PNL, depth_contact_maps_input_est = None, depth_contact_maps = None):\n",
    "    if CTRL_PNL['incl_pmat_cntct_input'] == True:\n",
    "        train_contact = np.copy(train_xa[:, 0:1, :, :]) #get the pmat contact map\n",
    "        train_contact[train_contact > 0] = 100.\n",
    "\n",
    "    if CTRL_PNL['depth_map_input_est'] == True:\n",
    "        depth_contact_maps_input_est = np.array(depth_contact_maps_input_est)\n",
    "        train_xa = np.concatenate((depth_contact_maps_input_est, train_xa), axis = 1)\n",
    "\n",
    "    print(np.shape(train_xa), CTRL_PNL['incl_pmat_cntct_input'])\n",
    "    if CTRL_PNL['incl_pmat_cntct_input'] == True:\n",
    "        train_xa = np.concatenate((train_contact, train_xa), axis=1)\n",
    "\n",
    "    print(np.shape(train_xa))\n",
    "    if CTRL_PNL['depth_map_labels'] == True:\n",
    "        depth_contact_maps = np.array(depth_contact_maps) #GROUND TRUTH\n",
    "        train_xa = np.concatenate((train_xa, depth_contact_maps), axis=1)\n",
    "\n",
    "    return train_xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the depth and contact mesh images (and possibly a pmat contact image) together\n",
    "train_xa_ = append_input_depth_contact(np.array(train_xa), CTRL_PNL, depth_contact_maps_input_est, depth_contact_maps)\n",
    "\n",
    "print(f'train_xa_.shape: {train_xa_.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. TensorPrepLib().prep_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_labels(y_flat, dat, num_repeats, z_adj, gender, is_synth, loss_vector_type, initial_angle_est, full_body_rot = False):\n",
    "    # printing\n",
    "    print(f'y_flat_arr.shape = {np.array(y_flat).shape}')\n",
    "    print(f'dat_array.shape = {np.array(dat).shape}')\n",
    "    print(f'z_adj = {z_adj}')\n",
    "    print(f'gender = {gender}')\n",
    "    print(f'is_synth = {is_synth}')\n",
    "    print(f'loss_vector_type = {loss_vector_type}')\n",
    "    print(f'initial_angle_est = {initial_angle_est}')\n",
    "    print(f'full_body_rot = {full_body_rot}')\n",
    "\n",
    "\n",
    "    if gender == \"f\":\n",
    "        g1 = 1\n",
    "        g2 = 0\n",
    "    elif gender == \"m\":\n",
    "        g1 = 0\n",
    "        g2 = 1\n",
    "    if is_synth == True:\n",
    "        s1 = 1\n",
    "    else:\n",
    "        s1 = 0\n",
    "    z_adj_all = np.array(24 * [0.0, 0.0, z_adj*1000])\n",
    "    z_adj_one = np.array(1 * [0.0, 0.0, z_adj*1000])\n",
    "\n",
    "    if is_synth == True and loss_vector_type != 'direct':\n",
    "        if dat is not None:\n",
    "            for entry in range(len(dat['markers_xyz_m'])):\n",
    "                c = np.concatenate((dat['markers_xyz_m'][entry][0:72] * 1000 + z_adj_all,\n",
    "                                    dat['body_shape'][entry][0:10],\n",
    "                                    dat['joint_angles'][entry][0:72],\n",
    "                                    dat['root_xyz_shift'][entry][0:3] + np.array([0.0, 0.0, z_adj]),\n",
    "                                    [g1], [g2], [s1],\n",
    "                                    [dat['body_mass'][entry]],\n",
    "                                    [(dat['body_height'][entry]-1.)*100],), axis=0)  # [x1], [x2], [x3]: female synth: 1, 0, 1.\n",
    "                if initial_angle_est == True:\n",
    "                    c = np.concatenate((c,\n",
    "                                        dat['betas_est'][entry][0:10],\n",
    "                                        dat['angles_est'][entry][0:72],\n",
    "                                        dat['root_xyz_est'][entry][0:3]), axis = 0)\n",
    "                    if full_body_rot == True:\n",
    "                        c = np.concatenate((c, dat['root_atan2_est'][entry][0:6]), axis = 0)\n",
    "                for i in range(num_repeats):\n",
    "                    y_flat.append(c)\n",
    "\n",
    "    elif is_synth == True and loss_vector_type == 'direct':\n",
    "        if dat is not None:\n",
    "            for entry in range(len(dat['markers_xyz_m_offset'])):\n",
    "                c = np.concatenate((np.array(9 * [0]),\n",
    "                                    dat['markers_xyz_m_offset'][entry][3:6] * 1000 + z_adj_one,  # TORSO\n",
    "                                    # fixed_torso_markers,  # TORSO\n",
    "                                    dat['markers_xyz_m_offset'][entry][21:24] * 1000 + z_adj_one,  # L KNEE\n",
    "                                    dat['markers_xyz_m_offset'][entry][18:21] * 1000 + z_adj_one,  # R KNEE\n",
    "                                    np.array(3 * [0]),\n",
    "                                    dat['markers_xyz_m_offset'][entry][27:30] * 1000 + z_adj_one,  # L ANKLE\n",
    "                                    dat['markers_xyz_m_offset'][entry][24:27] * 1000 + z_adj_one,  # R ANKLE\n",
    "                                    np.array(18 * [0]),\n",
    "                                    dat['markers_xyz_m_offset'][entry][0:3] * 1000 + z_adj_one,  # HEAD\n",
    "                                    # fixed_head_markers,\n",
    "                                    np.array(6 * [0]),\n",
    "                                    dat['markers_xyz_m_offset'][entry][9:12] * 1000 + z_adj_one,  # L ELBOW\n",
    "                                    dat['markers_xyz_m_offset'][entry][6:9] * 1000 + z_adj_one,  # R ELBOW\n",
    "                                    dat['markers_xyz_m_offset'][entry][15:18] * 1000 + z_adj_one,  # L WRIST\n",
    "                                    dat['markers_xyz_m_offset'][entry][12:15] * 1000 + z_adj_one,  # R WRIST\n",
    "                                    np.array(6 * [0]),\n",
    "                                    np.array(85 * [0]),\n",
    "                                    [g1], [g2], [s1],\n",
    "                                    [dat['body_mass'][entry]],\n",
    "                                    [(dat['body_height'][entry]-1.)*100],), axis=0)  # [x1], [x2], [x3]: female synth: 1, 0, 1.\n",
    "                if initial_angle_est == True:\n",
    "                    c = np.concatenate((c,\n",
    "                                        dat['betas_est'][entry][0:10],\n",
    "                                        dat['angles_est'][entry][0:72],\n",
    "                                        dat['root_xyz_est'][entry][0:3]), axis = 0)\n",
    "                for i in range(num_repeats):\n",
    "                    y_flat.append(c)\n",
    "\n",
    "\n",
    "    elif is_synth == False:\n",
    "        if dat is not None:\n",
    "            for entry in range(len(dat['markers_xyz_m'])):\n",
    "                c = np.concatenate((np.array(9 * [0]),\n",
    "                                    dat['markers_xyz_m'][entry][3:6] * 1000,  # TORSO\n",
    "                                    # fixed_torso_markers,  # TORSO\n",
    "                                    dat['markers_xyz_m'][entry][21:24] * 1000,  # L KNEE\n",
    "                                    dat['markers_xyz_m'][entry][18:21] * 1000,  # R KNEE\n",
    "                                    np.array(3 * [0]),\n",
    "                                    dat['markers_xyz_m'][entry][27:30] * 1000,  # L ANKLE\n",
    "                                    dat['markers_xyz_m'][entry][24:27] * 1000,  # R ANKLE\n",
    "                                    np.array(18 * [0]),\n",
    "                                    dat['markers_xyz_m'][entry][0:3] * 1000,  # HEAD\n",
    "                                    # fixed_head_markers,\n",
    "                                    np.array(6 * [0]),\n",
    "                                    dat['markers_xyz_m'][entry][9:12] * 1000,  # L ELBOW\n",
    "                                    dat['markers_xyz_m'][entry][6:9] * 1000,  # R ELBOW\n",
    "                                    dat['markers_xyz_m'][entry][15:18] * 1000,  # L WRIST\n",
    "                                    dat['markers_xyz_m'][entry][12:15] * 1000,  # R WRIST\n",
    "                                    np.array(6 * [0]),\n",
    "                                    np.array(85 * [0]),\n",
    "                                    [g1], [g2], [s1],\n",
    "                                    [dat['body_mass'][entry]],\n",
    "                                    [(dat['body_height'][entry]-1.)*100],), axis=0)  # [x1], [x2], [x3]: female real: 1, 0, 0.\n",
    "                if initial_angle_est == True:\n",
    "                    c = np.concatenate((c,\n",
    "                                        dat['betas_est'][entry][0:10],\n",
    "                                        dat['angles_est'][entry][0:72],\n",
    "                                        dat['root_xyz_est'][entry][0:3]), axis = 0)\n",
    "                for i in range(num_repeats):\n",
    "                    y_flat.append(c)\n",
    "\n",
    "    elif is_synth == 'real_nolabels':\n",
    "        s1 = 1\n",
    "        WEIGHT_LBS = 190.\n",
    "        HEIGHT_IN = 73.\n",
    "        weight_input = WEIGHT_LBS/2.20462\n",
    "        height_input = (HEIGHT_IN*0.0254 - 1)*100\n",
    "\n",
    "        if dat is not None:\n",
    "            for entry in range(len(dat['images'])):\n",
    "                c = np.concatenate((np.array(157 * [0]),\n",
    "                                    [g1], [g2], [s1],\n",
    "                                    [weight_input],\n",
    "                                    [height_input],), axis=0)  # [x1], [x2], [x3]: female synth: 1, 0, 1.\n",
    "                if initial_angle_est == True:\n",
    "                    c = np.concatenate((c,\n",
    "                                        dat['betas_est'][entry][0:10],\n",
    "                                        dat['angles_est'][entry][0:72],\n",
    "                                        dat['root_xyz_est'][entry][0:3]), axis = 0)\n",
    "                    if full_body_rot == True:\n",
    "                        c = np.concatenate((c, dat['root_atan2_est'][entry][0:6]), axis = 0)\n",
    "                for i in range(num_repeats):\n",
    "                    y_flat.append(c)\n",
    "\n",
    "\n",
    "    return y_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_flat = []\n",
    "\n",
    "train_y_flat = prep_labels(y_flat = train_y_flat, dat = dat_f, num_repeats = 1,\n",
    "                           z_adj = -0.075, gender = \"f\", is_synth = True,\n",
    "                           loss_vector_type = CTRL_PNL['loss_vector_type'],\n",
    "                           initial_angle_est = CTRL_PNL['adjust_ang_from_est'],\n",
    "                           full_body_rot = CTRL_PNL['full_body_rot'])\n",
    "\n",
    "print()\n",
    "print(f'np.array(train_y_flat).shape: {np.array(train_y_flat).shape}')\n",
    "print()\n",
    "\n",
    "train_y_flat = prep_labels(y_flat = train_y_flat, dat = dat_m, num_repeats = 1,\n",
    "                           z_adj = -0.075, gender = \"m\", is_synth = True,\n",
    "                            loss_vector_type = CTRL_PNL['loss_vector_type'],\n",
    "                            initial_angle_est = CTRL_PNL['adjust_ang_from_est'],\n",
    "                            full_body_rot = CTRL_PNL['full_body_rot'])\n",
    "\n",
    "print()\n",
    "print(f'np.array(train_y_flat).shape: {np.array(train_y_flat).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Normalize the input and labels, if __CTRL_PNL['normalize_input'] == True__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_network_input(train_xa, CTRL_PNL):\n",
    "\n",
    "    if CTRL_PNL['depth_map_input_est'] == True:\n",
    "        normalizing_std_constants = CTRL_PNL['norm_std_coeffs']\n",
    "\n",
    "        if CTRL_PNL['cal_noise'] == True:\n",
    "            normalizing_std_constants = normalizing_std_constants[1:] # here we don't precompute the contact\n",
    "\n",
    "        for i in range(train_xa.shape[1]):\n",
    "            train_xa[:, i, :, :] *= normalizing_std_constants[i]\n",
    "\n",
    "    else:\n",
    "        normalizing_std_constants = []\n",
    "        normalizing_std_constants.append(CTRL_PNL['norm_std_coeffs'][0])\n",
    "        normalizing_std_constants.append(CTRL_PNL['norm_std_coeffs'][4])\n",
    "        normalizing_std_constants.append(CTRL_PNL['norm_std_coeffs'][5])\n",
    "        normalizing_std_constants.append(CTRL_PNL['norm_std_coeffs'][6])\n",
    "        normalizing_std_constants.append(CTRL_PNL['norm_std_coeffs'][7])\n",
    "\n",
    "        if CTRL_PNL['cal_noise'] == True:\n",
    "            normalizing_std_constants = normalizing_std_constants[1:] # here we don't precompute the contact\n",
    "\n",
    "        for i in range(train_xa.shape[1]):\n",
    "            print(\"normalizing idx\", i)\n",
    "            train_xa[:, i, :, :] *= normalizing_std_constants[i]\n",
    "\n",
    "        # for i in range(x.shape[0]):\n",
    "        #    print torch.m\n",
    "\n",
    "    return train_xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_wt_ht(train_y_flat, CTRL_PNL):\n",
    "    # normalizing_std_constants = [1./30.216647403349857, 1./14.629298141231091]\n",
    "    train_y_flat = np.array(train_y_flat)\n",
    "    #y[:, 160] *= normalizing_std_constants[0]\n",
    "    #y[:, 161] *= normalizing_std_constants[1]\n",
    "    train_y_flat[:, 160] *= CTRL_PNL['norm_std_coeffs'][8]\n",
    "    train_y_flat[:, 161] *= CTRL_PNL['norm_std_coeffs'][9]\n",
    "\n",
    "    return train_y_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CTRL_PNL['normalize_input'] == True:\n",
    "    train_xa = normalize_network_input(train_xa, CTRL_PNL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CTRL_PNL['normalize_input'] == True:\n",
    "    train_y_flat = normalize_wt_ht(train_y_flat, CTRL_PNL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Convert the input (train_xa) & labels (train_y_flat) to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tensor = torch.Tensor(train_xa_)\n",
    "\n",
    "print(f'train_xa_.shape: {train_xa_.shape}')\n",
    "print(f'train_x_tensor.shape: {train_x_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_tensor = torch.Tensor(train_y_flat)\n",
    "\n",
    "print(f'np.array(train_y_flat).shape: {np.array(train_y_flat).shape}')\n",
    "print(f'train_y_tensor.shape: {train_y_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Prepare Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_x_tensor, train_y_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, CTRL_PNL['batch_size'], shuffle=CTRL_PNL['shuffle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Print;  \n",
    "- input(x) & output(y) shapes  \n",
    "- Dataset & DataLoader lengths  \n",
    "- Model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_x_tensor.shape: {train_x_tensor.shape}')\n",
    "print(f'train_y_tensor.shape: {train_y_tensor.shape}')\n",
    "print(f': {model_pkl_file_path}')\n",
    "\n",
    "print(f'train_dataset len: {len(train_dataset)}')\n",
    "print(f'train_loader len: {len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. def __val_general__():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __model = load_model()__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __dd = ready_arguments()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_arguments(model_pkl_file_path):\n",
    "    if not isinstance(model_pkl_file_path, dict):\n",
    "        with open(model_pkl_file_path, 'rb') as f:\n",
    "            dd = pickle.load(f, encoding='latin1')\n",
    "    else:\n",
    "        dd = model_pkl_file_path\n",
    "\n",
    "#     backwards_compatibility_replacements(dd)\n",
    "# def backwards_compatibility_replacements(dd):\n",
    "    # replacements\n",
    "    if 'default_v' in dd:\n",
    "        dd['v_template'] = dd['default_v']\n",
    "        del dd['default_v']\n",
    "    if 'template_v' in dd:\n",
    "        dd['v_template'] = dd['template_v']\n",
    "        del dd['template_v']\n",
    "    if 'joint_regressor' in dd:\n",
    "        dd['J_regressor'] = dd['joint_regressor']\n",
    "        del dd['joint_regressor']\n",
    "    if 'blendshapes' in dd:\n",
    "        dd['posedirs'] = dd['blendshapes']\n",
    "        del dd['blendshapes']\n",
    "    if 'J' not in dd:\n",
    "        dd['J'] = dd['joints']\n",
    "        del dd['joints']\n",
    "#     backwards_compatibility_replacements(dd)\n",
    "\n",
    "\n",
    "    # defaults\n",
    "    if 'bs_style' not in dd:\n",
    "        dd['bs_style'] = 'lbs'    \n",
    "        \n",
    "    want_shapemodel = 'shapedirs' in dd\n",
    "    nposeparms = dd['kintree_table'].shape[1]*3\n",
    "\n",
    "    if 'trans' not in dd:\n",
    "        dd['trans'] = np.zeros(3)\n",
    "    if 'pose' not in dd:\n",
    "        dd['pose'] = np.zeros(nposeparms)\n",
    "    if 'shapedirs' in dd and 'betas' not in dd:\n",
    "        dd['betas'] = np.zeros(dd['shapedirs'].shape[-1])\n",
    "\n",
    "    for s in ['v_template', 'weights', 'posedirs', 'pose', 'trans', 'shapedirs', 'betas', 'J']:\n",
    "        if (s in dd) and not hasattr(dd[s], 'dterms'):\n",
    "            dd[s] = ch.array(dd[s])\n",
    "\n",
    "    if want_shapemodel:\n",
    "        dd['v_shaped'] = dd['shapedirs'].dot(dd['betas'])+dd['v_template']\n",
    "        v_shaped = dd['v_shaped']\n",
    "        J_tmpx = MatVecMult(dd['J_regressor'], v_shaped[:,0])        \n",
    "        J_tmpy = MatVecMult(dd['J_regressor'], v_shaped[:,1])        \n",
    "        J_tmpz = MatVecMult(dd['J_regressor'], v_shaped[:,2])        \n",
    "        dd['J'] = ch.vstack((J_tmpx, J_tmpy, J_tmpz)).T    \n",
    "        dd['v_posed'] = v_shaped + dd['posedirs'].dot(posemap(dd['bs_type'])(dd['pose']))\n",
    "    else:    \n",
    "        dd['v_posed'] = dd['v_template'] + dd['posedirs'].dot(posemap(dd['bs_type'])(dd['pose']))\n",
    "            \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = ready_arguments(model_pkl_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print output of the loaded pickle file\n",
    "\n",
    "print(f'os.getcwd(): {os.getcwd()}')\n",
    "os.chdir('../')\n",
    "from z_utils import print_dict\n",
    "os.chdir('PressurePose')\n",
    "print(f'os.getcwd(): {os.getcwd()}')\n",
    "\n",
    "print_dict(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remaining code from __load_model()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'pose': dd['pose'],\n",
    "    'v': dd['v_posed'],\n",
    "    'J': dd['J'],\n",
    "    'weights': dd['weights'],\n",
    "    'kintree_table': dd['kintree_table'],\n",
    "    'xp': ch,\n",
    "    'want_Jtr': True,\n",
    "    'bs_style': dd['bs_style']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, Jtr = verts_core(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model.shape: {model.shape}')\n",
    "print(f'Jtr.shape: {Jtr.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model + dd['trans'].reshape((1,3))\n",
    "model.J_transformed = Jtr + dd['trans'].reshape((1,3))\n",
    "\n",
    "for k, v in list(dd.items()):\n",
    "    setattr(model, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End __load_model()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyRender = libPyRender.pyRenderMesh(render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will loop a total = training_images/batch_size times\n",
    "for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "    if batch_idx in [0, 1]: continue\n",
    "\n",
    "    betas_gt = torch.mean(batch[1][:, 72:82], dim = 0).numpy()\n",
    "    angles_gt = torch.mean(batch[1][:, 82:154], dim = 0).numpy()\n",
    "    root_shift_est_gt = torch.mean(batch[1][:, 154:157], dim = 0).numpy()\n",
    "\n",
    "    pmat = batch[0][0, 1, :, :].clone().numpy() # * 11.70153502792190\n",
    "\n",
    "    for beta in range(betas_gt.shape[0]):\n",
    "        model.betas[beta] = betas_gt[beta]\n",
    "\n",
    "    for angle in range(angles_gt.shape[0]):\n",
    "        model.pose[angle] = angles_gt[angle]\n",
    "\n",
    "\n",
    "    # ground truth human mesh vertices\n",
    "    smpl_verts_gt = np.array(model.r)\n",
    "\n",
    "    for s in range(root_shift_est_gt.shape[0]):\n",
    "        smpl_verts_gt[:, s] += (root_shift_est_gt[s] - float(model.J_transformed[0, s]))\n",
    "\n",
    "    smpl_verts_gt = np.concatenate(\n",
    "        (smpl_verts_gt[:, 1:2] - 0.286 + 0.0143,\n",
    "            smpl_verts_gt[:, 0:1] - 0.286 + 0.0143,\n",
    "            0.0 - smpl_verts_gt[:, 2:3]), axis=1)\n",
    "\n",
    "    # mesh faces\n",
    "    smpl_faces = np.array(model.f)\n",
    "\n",
    "    # this gets the joint cartesian positions. no code here to visualize.\n",
    "    joint_cart_gt = np.array(model.J_transformed).reshape(24, 3)\n",
    "    for s in range(root_shift_est_gt.shape[0]):\n",
    "        joint_cart_gt[:, s] += (root_shift_est_gt[s] - float(model.J_transformed[0, s]))\n",
    "\n",
    "\n",
    "\n",
    "    if red_verts == False:\n",
    "    # this code renders the whole ground truth mesh.\n",
    "        pyRender.render_3D_data(camera_point = None, pmat = pmat, smpl_verts_gt = smpl_verts_gt,\n",
    "                                        smpl_faces = smpl_faces, segment_limbs = seg_limbs)\n",
    "    else:\n",
    "        # this code renders only camera-facing vertices in the mesh\n",
    "        camera_point = [1.09898028, 0.46441343, -CAM_BED_DIST]\n",
    "        pyRender.render_3D_data(camera_point=camera_point, pmat=pmat, smpl_verts_gt=smpl_verts_gt,\n",
    "                                        smpl_faces=smpl_faces, segment_limbs = seg_limbs)\n",
    "\n",
    "    # time.sleep(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
